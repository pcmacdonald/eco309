{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Mc-Call Job Search Model with Separation\n",
    "\n",
    "We consider here a very simple job-search model, with separation. Our goal consists in solving this model using a policy iteration algorithm. Some background on the McCall and numerical ideas are discussed on the [QuantEcon](`https://julia.quantecon.org/mccall_model.html`) website.\n",
    "\n",
    "There is a single worker who can be either employed (\"e\") or unemployed (\"u\") in any period.\n",
    "\n",
    "When unemployed, the jobless worker receives unemployment benefits $c_t=\\alpha>0$ in every period as long as he stays unemployed. He also receives a salary offer $w_t$ which is drawn from a discrete i.i.d. distribution and takes values $w_1, ..., w_K$ with probabilities $p_1, ... p_K$ respectively.\n",
    "\n",
    "When an unemployed worker accepts an offer in period $t$, he gets the salary $w_t$ and becomes employed. He then keeps his salary $w_t$ as long as he stays employed (for $s\\geq t$, $c_s=w_t$ if $t$ is the date at which worker got the current job); in each period he has a probability $\\lambda$ of becoming unemployed in the next period and remains employed otherwise.\n",
    "\n",
    "When a worker receives a given amount $x$ his perceived utility is $U(x)=\\frac{x^{1-\\gamma}}{1-\\gamma}$ with $\\gamma>1.0$. A worker discounts the future at a rate $\\beta \\in [0,1[$. As a result, in any period $t_0$ workers seek to maximize $\\sum_{t\\geq t_0}^{\\infty} U(c_t)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Define a parameter type `Parameter`, with fields $\\alpha$, $\\beta$, $\\gamma$, $K$, $\\sigma$, $\\lambda$. Create a parameter variable $\\omega$ with $\\alpha=0.5$, $\\beta=0.96$, $\\gamma=4$, $K=10$, $\\sigma=0.6$, $\\lambda=0.015$__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Parameter\n",
    "    Î±::Float64\n",
    "    Î²::Float64\n",
    "    Î³::Float64\n",
    "    K::Float64\n",
    "    Ïƒ::Float64\n",
    "    Î»::Float64\n",
    "end\n",
    "\n",
    "Ï‰ = Parameter(0.5, 0.96, 4, 10, 0.6, 0.015)\n",
    "\n",
    "K=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What is the uniform distribution, whose mean is 1 and standard deviation is $\\sigma$? Write a function `discrete_uniform(Ïƒ::Float64, K::Int64)::Tuple{Vector{Float64} Vector{Float64}}` to discretize it, using $K$ points. The function should return two vectors `w` and `p` of floats of the same size `K`. Check the results satisfy the right conditions (uniformity, standard deviation).__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrete uniform distribution between $a$ and $b$:<br>\n",
    "Mean is 1:\n",
    "$$\\frac{a+b}{2} = 1 \\iff b=2-a$$\n",
    "\n",
    "Standard deviation is $\\sigma$:\n",
    "$$\\frac{(b-a+1)^2 -1}{12} = \\sigma^2 \\iff \\frac{(2-a-a+1)^2 -1}{12}=\\sigma^2 \\iff \\frac{8 + 4a^2 -12a}{12}=\\sigma^2 \\iff a^2 -3a + 2 - 3\\sigma^2 = 0$$\n",
    "$\\Delta = 9  + 12\\sigma^2 - 8 = 12 \\sigma^2 +1$, hence:\n",
    "$$x_1 = \\frac{3 + \\sqrt{1+12\\sigma^2}}{2}, x_2 = \\frac{3 - \\sqrt{1+12\\sigma^2}}{2}$$\n",
    "\n",
    "We check that if $\\sigma = 0$, $a = b = 1$:\n",
    "$$x_1 = \\frac{3 + \\sqrt{1+12\\sigma^2}}{2} =  \\frac{3 + \\sqrt{1}}{2} = \\frac{4}{2} = 2$$\n",
    "$$x_2 = \\frac{3 - \\sqrt{1+12\\sigma^2}}{2} =  \\frac{3 - \\sqrt{1}}{2} = \\frac{2}{2} = 1$$\n",
    "\n",
    "So, $a= x_2$, $b = 2 - x_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discrete_uniform (generic function with 1 method)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function discrete_uniform(Ïƒ::Float64, K::Int64)\n",
    "    a = (3 - sqrt(1 + 12*Ïƒ^2))/2;\n",
    "    #print(\"a\", a,\"b\", 2-a);\n",
    "    r1 = [a + ((2-2*a)/(K-1))*k for k in 0:K-1];\n",
    "    r2 = [1/K for k in 0:K-1]\n",
    "    \n",
    "    return (r1, r2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The optimal decision of a worker is characterized by two value functions: $V^E(w)$ is the value of being employed at wage $w$ and $V^U(w)$ the value of being unemployed, while receiving job offer $w_t$. In Julia, both $V^U$ and $V^E$ will be represented by arrays `V_U` and `V_E` of size `K`.\n",
    "\n",
    "A policy `g(w)` is a binary choice in the unemployed state: accept or reject an offer $w_t$. It will then naturally be represented by a boolean array (type `zeros(Bool, K)` to initialize one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Bool,1}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=5\n",
    "g = zeros(Bool,K)\n",
    "typeof(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Given a policy $g$, write down the recursive equations which defines the corresponding value functions $V^{U,g}(w)$ and $V^{E,g}(w)$.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VU (generic function with 1 method)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function VE(g::Array)\n",
    "    W,P = discrete_uniform(Ï‰.Ïƒ,K)\n",
    "    return [(W[i]^(1-Ï‰.Î³))/(1-Ï‰.Î³) for i in 1::K]\n",
    "    #return [(W[i]^(1-Ï‰.Î³))/(1-Ï‰.Î³) + Î²*((1-Î»)*VE(g)[i] + Î»*sum(VU(g))/K) for i in 1::K]\n",
    "end\n",
    "\n",
    "function VU(g)\n",
    "    W,P = discrete_uniform(Ï‰.Ïƒ,K)\n",
    "    return [g[i]*VE(g)[i] + (1-g[i])*((Î±^(1-Ï‰.Î³))/(1-Ï‰.Î³) + Î²*VU(g)[i]) for i in 1::K]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Write a function which takes a guess $V^{U,g}(w)$ and $V^{E,g}(w)$ and a policy function $g$ as arguments (and other model parameters) and updates the values, according to the updating equations. This function could have signature `value_update(V_U::Vector{Float64}, V_E::Vector{Float64}, g::Vector{Bool}, Ï‰::Parameter, w::Vector{Float64}, p::Vector{Float64})::Vector{Float64}` where the returned vector has the same size as the supplied ones.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${V^E}(w)= U(w)+ \\beta((1-\\lambda)V^E(w)+\\lambda\\mathbb{E}[V^U(x)])$$\n",
    "<br>\n",
    "$$V^U(w) = \\text{max}(V^E(w), U(\\alpha) + \\beta V^U(w)) = g V^E(w) + (1-g) (U(\\alpha) + \\beta V^U(w))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value_update (generic function with 1 method)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=10\n",
    "                        \n",
    "function value_update(V_U::Vector{Float64}, V_E::Vector{Float64}, g::Vector{Bool}, Ï‰::Parameter, w::Vector{Float64}, p::Vector{Float64})\n",
    "    VU_guess = V_U\n",
    "    VE_guess = V_E\n",
    "    VU_update =   [g[i]*VE_guess[i] + (1-g[i])*((Î±^(1-Ï‰.Î³))/(1-Ï‰.Î³)) + Î²*VU_guess[i] for i in 1::K]                          \n",
    "    VE_update =  [(w[i]^(1-Ï‰.Î³))/(1-Ï‰.Î³) + Î²*((1-Î»)*VE_guess[i] + Î»*sum(VU_guess)/K) for i in 1::K]\n",
    "    return (VU_update, VE_update)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Write a function `eval_policy(g::Vector{Bool}, Ï‰::Parameter, w::Vector{Float64}, p::Vector{Float64}, Î·::Float64)::Tuple{Vector{Float64}, Vector{Float64}}` which iterates on `value_update` find the values that satisfy the evaluation equations for policy `g`.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TypeError: in typeassert, expected Type, got Int64",
     "output_type": "error",
     "traceback": [
      "TypeError: in typeassert, expected Type, got Int64",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[185]:1"
     ]
    }
   ],
   "source": [
    "VU_guess = [Ï‰.Î± for i in 1::K ]\n",
    "VE_guess = [w[i] for i in 1::K]\n",
    "        \n",
    "function eval_policy(g::Vector{Bool}, Ï‰::Parameter, w::Vector{Float64}, p::Vector{Float64}, Î·::Float64)\n",
    "    VU_update =  [g[i]*VE_guess[i] + (1-g[i])*((Î±^(1-Ï‰.Î³))/(1-Ï‰.Î³)) + Î²*VU_guess[i] for i in 1::K]                               \n",
    "    VE_update = [(w[i]^(1-Ï‰.Î³))/(1-Ï‰.Î³) + Î²*((1-Î»)*VE_guess[i] + Î»*sum(VU_guess)/K) for i in 1::K]\n",
    "                            \n",
    "    while 0.5*(abs(VU_update- VU_guess) + abs(VU_update- VU_guess))>Î·\n",
    "        VU_guess = VU_update\n",
    "        VE_guess = VE_update\n",
    "        VU_update =  [g[i]*VE_guess[i] + (1-g[i])*((Î±^(1-Ï‰.Î³))/(1-Ï‰.Î³)) + Î²*VU_guess[i] for i in 1::K]                               \n",
    "        VE_update = [(w[i]^(1-Ï‰.Î³))/(1-Ï‰.Î³) + Î²*((1-Î»)*VE_guess[i] + Î»*sum(VU_guess)/K) for i in 1::K]                                          \n",
    "    end\n",
    "    return (VU_update, VE_update)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__Write a function `improve_policy(g::Vector{Bool}, V_U::Vector{Bool}, V_E::Vector{Bool}, Ï‰::Parameter, w::Vector{Float64}, p::Vector{Float64}, Î·::Float64)::Vector{Float64}` which returns the improved policy given guesses for the value function(s) at for $t+1$.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "improve_policy (generic function with 2 methods)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function improve_policy(g::Vector{Bool}, V_U::Vector{Float64}, V_E::Vector{Float64}, Ï‰::Parameter, w::Vector{Float64}, p::Vector{Float64}, Î·::Float64)\n",
    "    VU_guess = V_U\n",
    "    VE_guess = V_E\n",
    "    \n",
    "    VU_update, VE_update = eval_policy(g, Ï‰, w, p, Î·)\n",
    "    \n",
    "    g= zeros(Bool,10)\n",
    "    \n",
    "    for i in 1::K\n",
    "        if VE_update[i] > (Î±^(1-Ï‰.Î³))/(1-Ï‰.Î³) + Î²*VU_update[i]\n",
    "            g[i] = 1\n",
    "        else\n",
    "            g[i] = 0\n",
    "        end\n",
    "    end\n",
    "    return g\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Implement the policy function algorithm. Print the successive approximation errors and comment on the convergence speed.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "policy_function (generic function with 2 methods)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function policy_function( V_U::Vector{Float64}, V_E::Vector{Float64}, Ï‰::Parameter, w::Vector{Float64}, p::Vector{Float64}, Î·::Float64)\n",
    "    g_guess = zeros(Bool,K)\n",
    "    g_update = improve_policy(g_guess, V_U, V_E,Ï‰,w,p,Î·)\n",
    "    \n",
    "    g_s = [g_guess, g_update]\n",
    "    \n",
    "    while abs(g_guess-g_update)>Î·\n",
    "        g_guess = g_update\n",
    "        g_update = improve_policy(g_guess, V_U, V_E,Ï‰,w,p,Î·)\n",
    "        g_s += [g_update]\n",
    "    end\n",
    "    return g_s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array{Float64,1}Array{Float64,1}ParameterArray{Float64,1}Array{Float64,1}Float64"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TypeError: in typeassert, expected Type, got Int64",
     "output_type": "error",
     "traceback": [
      "TypeError: in typeassert, expected Type, got Int64",
      "",
      "Stacktrace:",
      " [1] eval_policy(::Array{Bool,1}, ::Parameter, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at .\\In[167]:2",
      " [2] improve_policy(::Array{Bool,1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Parameter, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at .\\In[188]:5",
      " [3] policy_function(::Array{Float64,1}, ::Array{Float64,1}, ::Parameter, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at .\\In[193]:3",
      " [4] top-level scope at In[197]:7"
     ]
    }
   ],
   "source": [
    "w, p = discrete_uniform(Ï‰.Ïƒ,K)\n",
    "\n",
    "VU_GUESS = [Ï‰.Î±,Ï‰.Î±,Ï‰.Î±,Ï‰.Î±,Ï‰.Î±,Ï‰.Î±,Ï‰.Î±,Ï‰.Î±,Ï‰.Î±,Ï‰.Î±]\n",
    "VE_GUESS = w\n",
    "\n",
    "print(typeof(VU_GUESS),typeof(VE_GUESS),typeof(Ï‰),typeof(w),typeof(p),typeof(0.1))\n",
    "policy_function(VU_GUESS, VE_GUESS, Ï‰, w, p, 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Neoclassical growth model (2)\n",
    "\n",
    "We consider here, another deterministic version of the neoclassical growth model, but propose a slightly different solution method.\n",
    "\n",
    "A representative agent uses capital $k_t$ to produce $y_t$ using the following production function:\n",
    "\n",
    "$$y_t = k_t^{\\alpha}$$\n",
    "\n",
    "He chooses to consume an amount $c_t \\in ]0, y_t]$ and invests what remains:\n",
    "\n",
    "$$i_t = y_t - c_t$$.\n",
    "\n",
    "He accumulates capital $k_t$ according to:\n",
    "\n",
    "$$k_{t+1} = \\left( 1-\\delta \\right) k_{t} + i_{t}$$\n",
    "\n",
    "where $\\delta$ is the depreciation rate and $i_t$ is the amount invested.\n",
    "\n",
    "The goal of the representative agent is to maximize:\n",
    "\n",
    "$$\\sum_{t\\geq 0} \\beta^t U(c_t)$$\n",
    "\n",
    "where $U(x)=\\frac{x^{1-\\gamma}}{1-\\gamma}$ and $\\beta<1$ is the discount factor.\n",
    "\n",
    "Since the problem is time homogenous, the value function depends on available capital only and satisfies the following Bellman equation:\n",
    "\n",
    "$$V\\left(\\underbrace{k}_{k_t}\\right) = \\max_{c\\in[0,1[} U(c) + \\beta V\\left(\\underbrace{(1-\\delta)k + \\underbrace{(k^{\\alpha}-c)}_{y_{t+1}}}_{k_{t+1}}\\right)$$\n",
    "\n",
    "Our goal is to obtain a smooth approximation of $k$ and $V$ by using interpolations techniques.\n",
    "\n",
    "For this model, using the dynamic first-order conditions, one can show the deterministic steady-state of the model satisfies $1=\\beta \\left( (1-\\delta) + \\alpha k^{\\alpha -1} \\right)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a suitable Parameter type to hold the parameters. Write a function `steady_state(p::Parameter)` to compute the steady-state capital `kbar` and the corresponding steady-state consumption `cbar`__ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steady-state capital:\n",
    "$$1=\\beta \\left( (1-\\delta) + \\alpha \\bar{k}^{\\alpha -1} \\right) \\iff \\bar{k} = (\\frac{1 - \\beta(1-\\delta)}{\\beta \\alpha})^{\\frac{1}{a-1}}$$\n",
    "Steady-state consumption:\n",
    "$$(1-\\delta)\\bar{k} + \\bar{k}^a -c = \\bar{k} \\iff \\bar{c} = \\bar{k}^a - \\delta \\bar{k}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Param(0.5, 0.05, 0.96, 4.0)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Param\n",
    "    a::Float64\n",
    "    Î´::Float64\n",
    "    Î²::Float64\n",
    "    Î³::Float64\n",
    "end\n",
    "\n",
    "p=Param(0.5,0.05,0.96, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "steady_state (generic function with 2 methods)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function steady_state(p::Param)\n",
    "    kbar = ((1-p.Î²*(1-p.Î´))/(p.Î²*p.Î±))^(1/(p.a-1))\n",
    "    cbar = kbar^p.a - p.Î´ * kbar\n",
    "    \n",
    "    return (kbar,cbar)\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Set $N=10$ and define a reasonable grid `kgrid=range(kmin, kmax; length=N)` to approximate capital $k$.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5:0.16666666666666666:2.0"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N=10\n",
    "\n",
    "#in trillions\n",
    "kmin = 0.5\n",
    "kmax = 2\n",
    "\n",
    "kgrid = range(kmin, kmax; length = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The unknown value function is represented as a `N` elements arrays. Define `Vi(k,p)=U(Î´ * k^Î±)/(1-ð›½)` and compute the initial guess `V0 = [Vi(k,p) for k in kgrid]`. Define a finer grid `ktest=range(kmin, kmax;length=1000)` and find the values of `Vi` on it by  using `Interpolations.jl` library to interpolate `V0` between the points of `kgrid`.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `C:\\Users\\phoeb\\.julia\\registries\\General`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [========================================>]  100.0 % %]  22.7 % %\u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==================>                      ]  44.8 %>                  ]  53.0 %\u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==========================>              ]  63.4 %           ]  71.3 %\u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=================================>       ]  80.4 % %]  98.4 %\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m AxisAlgorithms â”€â”€â”€ v1.0.0\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Ratios â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m WoodburyMatrices â”€ v0.5.2\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m OffsetArrays â”€â”€â”€â”€â”€ v1.1.0\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Interpolations â”€â”€â”€ v0.12.10\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `C:\\Users\\phoeb\\.julia\\environments\\v1.4\\Project.toml`\n",
      " \u001b[90m [a98d9a8b]\u001b[39m\u001b[92m + Interpolations v0.12.10\u001b[39m\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `C:\\Users\\phoeb\\.julia\\environments\\v1.4\\Manifest.toml`\n",
      " \u001b[90m [13072b0f]\u001b[39m\u001b[92m + AxisAlgorithms v1.0.0\u001b[39m\n",
      " \u001b[90m [a98d9a8b]\u001b[39m\u001b[92m + Interpolations v0.12.10\u001b[39m\n",
      " \u001b[90m [6fe1bfb0]\u001b[39m\u001b[92m + OffsetArrays v1.1.0\u001b[39m\n",
      " \u001b[90m [c84ed2f1]\u001b[39m\u001b[92m + Ratios v0.4.0\u001b[39m\n",
      " \u001b[90m [efce3f68]\u001b[39m\u001b[92m + WoodburyMatrices v0.5.2\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"Interpolations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "â”Œ Info: Precompiling Interpolations [a98d9a8b-a2ab-59e6-89dd-64a1c18fca59]\n",
      "â”” @ Base loading.jl:1260\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "syntax: unexpected \"=\"",
     "output_type": "error",
     "traceback": [
      "syntax: unexpected \"=\"",
      ""
     ]
    }
   ],
   "source": [
    "function Vi(k,p)\n",
    "   return (((p.Î´*k^p.a)^(1-p.Î³))/(1-p.Î³))/(1-p.Î²) \n",
    "end\n",
    "\n",
    "V0 = [Vi(k,p) for k in kgrid]\n",
    "\n",
    "ktest=range(kmin, kmax;length=1000)\n",
    "\n",
    "using Interpolations\n",
    "itp = = interpolate(ktest, V0, Gridded(Linear()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__Compute a Bellman improvement function `bellman(V0::Vector{Float64}, p::Parameter, kgrid)::Tuple{Vector{Float64}, Vector{Float64}}` which does the following steps:__\n",
    "\n",
    "- take an initial guess `V0` for the value function\n",
    "\n",
    "- at each grid point from kvec, optimize nonlinearly, the function $c \\rightarrow U(c) + \\beta V\\left((1-\\delta)k + (k^{\\alpha}-c)\\right)$ for each capital level in the grid `kvec`. In this expression the function `V()` interpolates `V0` defined on `kvec` on any point `k` so that the resulting function is continuous. \n",
    "\n",
    "- return the updated value and investment rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function bellman(V0::Vector{Float64}, p::Param, kgrid)\n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__Write a value interation function `vfi(N, p)` which solves the model defined by parameter `p` using the value function algorithm. The function should return the value function and the policy rule.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Plot the solution. Comment.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bonus 1: plot a graph showing the convergence back to the steady-state__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bonus 2: implement the policy iteration algorithm by adding an evaluation step in the `vfi` function.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
